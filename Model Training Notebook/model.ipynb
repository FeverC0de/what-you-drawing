{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = [\"circle.npy\", \"square.npy\", \"star.npy\", \"triangle.npy\"]\n",
    "\n",
    "class_names = [\"circle\", \"square\", \"star\", \"triangle\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Numpy Loading Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load(dir, reshaped, files):\n",
    "    data = []\n",
    "    for file in files:\n",
    "        f = np.load(dir + file)\n",
    "        if reshaped:\n",
    "            new_f = []\n",
    "            for i in range(len(f)):\n",
    "                x = np.reshape(f[i], (28, 28))\n",
    "                x = np.expand_dims(x, axis = 0)\n",
    "                x = np.reshape(f[i], (28, 28, 1))\n",
    "                new_f.append(x)\n",
    "            f = new_f\n",
    "        data.append(f)\n",
    "    return data\n",
    "\n",
    "def set_limit(arrays, n):\n",
    "    new = []\n",
    "    for array in arrays:\n",
    "        i = 0\n",
    "        for item in array:\n",
    "            if i == n:\n",
    "                break\n",
    "            new.append(item)\n",
    "            i += 1\n",
    "    return new\n",
    "\n",
    "def make_labels(N1, N2):\n",
    "    labels = []\n",
    "    for i in range(N1):\n",
    "        labels += [i] * N2\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shapes = load(\"data/\", False, [\"circle.npy\"])\n",
    "\n",
    "img = shapes[0][1]\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "img = np.reshape(img, (28, 28))\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fe5b236170>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 5000\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "shapes = load(\"data/\", True, class_data)\n",
    "\n",
    "shapes = set_limit(shapes, N)\n",
    "\n",
    "plt.imshow(shapes[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['circle', 'square', 'star', 'triangle']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "target_dir = \"data\"\n",
    "\n",
    "def get_classes(dir):\n",
    "    class_names = sorted([os.path.splitext(entry.name)[0] for entry in os.scandir(dir)])\n",
    "    return class_names\n",
    "\n",
    "\n",
    "classes = get_classes(target_dir)\n",
    "\n",
    "classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root = \"./data\", max_samples = 5000):\n",
    "    files = Path(root).glob('*.npy')\n",
    "\n",
    "    x = np.empty([0, 784], dtype = np.uint8)\n",
    "    y = np.empty([0], dtype = np.longlong)\n",
    "    class_names = []\n",
    "\n",
    "    for idx, file in enumerate(sorted(files)):\n",
    "        data = np.load(file, mmap_mode= 'r')\n",
    "        data = data[0: max_samples, :]\n",
    "        labels = np.full(data.shape[0], idx)\n",
    "        x = np.concatenate((x, data), axis = 0)\n",
    "        y = np.append(y, labels)\n",
    "\n",
    "        class_names.append(file.stem)\n",
    "\n",
    "    return x, y, class_names\n",
    "\n",
    "class_names\n",
    "\n",
    "class QuickDrawDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,root, max_samples = 5000):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.max_samples = max_samples\n",
    "\n",
    "        self.X, self.Y, self.classes = load_data(self.root, self.max_samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = (self.X[idx] /255.).astype(np.float32).reshape(1, 28, 28)\n",
    "        y = self.Y[idx]\n",
    "\n",
    "        return torch.from_numpy(x), y.item()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        x = torch.stack([item[0] for item in batch])\n",
    "        y = torch.LongTensor([item[1] for item in batch])\n",
    "        return {'pixel_values' : x, 'labels': y}\n",
    "    \n",
    "    def split(self, pct = 0.1):\n",
    "        num_classes = len(self.classes)\n",
    "        indices = torch.randperm(len(self)).tolist()\n",
    "        n_val = math.floor(len(indices) * pct)\n",
    "        train_ds = torch.utils.data.Subset(self, indices[:-n_val])\n",
    "        val_ds = torch.utils.data.Subset(self, indices[-n_val:])\n",
    "        return train_ds, val_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "max_samples = 20000\n",
    "train_val_split_pct = 0.1\n",
    "\n",
    "ds = QuickDrawDataset(data_dir, max_samples)\n",
    "num_classes = len(ds.classes)\n",
    "train_ds, val_ds = ds.split(train_val_split_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, 3, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64, 128, 3, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(128, 256, 3, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2304, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, num_classes),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_batches = 256\n",
    "\n",
    "train_batches = DataLoader(train_ds,\n",
    "                           batch_size=num_batches,\n",
    "                           shuffle=True)\n",
    "test_batches = DataLoader(val_ds, \n",
    "                          batch_size = num_batches,\n",
    "                          shuffle= True)\n",
    "\n",
    "train_batch_features = next(iter(train_batches))\n",
    "x , y = train_batch_features\n",
    "\n",
    "x.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nick-Uni\\Desktop\\Shapes_Project\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nick-Uni\\Desktop\\Shapes_Project\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.conv1 = nn.Conv2d(1, model.conv1.out_channels, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model : torch.nn.Module,\n",
    "                data_loader: torch.utils.data.DataLoader,\n",
    "                loss_fn: torch.nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                accuracy_fn,\n",
    "                device: torch.device):\n",
    "    \n",
    "    \n",
    "    train_loss, train_acc = 0 , 0\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "\n",
    "        X, y = X.to(device, non_blocking = True), y.to(device, non_blocking = True)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        \n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy_fn(y_true = y,\n",
    "                                 y_pred = y_pred.argmax(dim = 1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    return train_loss , train_acc\n",
    "    \n",
    "\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device : torch.device):\n",
    "    \n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "\n",
    "            X, y = X.to(device, non_blocking = True), y.to(device, non_blocking = True)\n",
    "\n",
    "            test_pred = model(X)\n",
    "\n",
    "            test_loss += loss_fn(test_pred, y).item()\n",
    "            test_acc += accuracy_fn(y_true = y, y_pred = test_pred.argmax(dim = 1))\n",
    "\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "\n",
    "        print(f\"Test Loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
    "\n",
    "        return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(),\n",
    "                            lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format). \n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m     loss_train ,acc_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43maccuracy_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maccuracy_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     atrain_loss_list\u001b[38;5;241m.\u001b[39mappend(loss_train)\n\u001b[0;32m     24\u001b[0m     atrain_acc_list\u001b[38;5;241m.\u001b[39mappend(acc_train)\n",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, data_loader, loss_fn, optimizer, accuracy_fn, device)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_step\u001b[39m(model : torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m      2\u001b[0m                 data_loader: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader,\n\u001b[0;32m      3\u001b[0m                 loss_fn: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m      4\u001b[0m                 optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m      5\u001b[0m                 accuracy_fn,\n\u001b[0;32m      6\u001b[0m                 device: torch\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[0;32m      9\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m , \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n",
      "File \u001b[1;32mc:\\Users\\Nick-Uni\\Desktop\\Shapes_Project\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nick-Uni\\Desktop\\Shapes_Project\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nick-Uni\\Desktop\\Shapes_Project\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nick-Uni\\Desktop\\Shapes_Project\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Nick-Uni\\Desktop\\Shapes_Project\\venv\\lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "train_time_start_model_2 = timer()\n",
    "atrain_loss_list = []\n",
    "atrain_acc_list = []\n",
    "\n",
    "atest_loss_list = []\n",
    "atest_acc_list = []\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n\")\n",
    "    loss_train ,acc_train = train_step(data_loader = train_batches,\n",
    "                    model = model,\n",
    "                    loss_fn = loss_fn,\n",
    "                    optimizer = optimizer,\n",
    "                    accuracy_fn = accuracy_fn,\n",
    "                    device = device)\n",
    "    \n",
    "    atrain_loss_list.append(loss_train)\n",
    "    atrain_acc_list.append(acc_train)\n",
    "                   \n",
    "    loss_test, acc_test = test_step(data_loader = test_batches,\n",
    "              model = model,\n",
    "              loss_fn = loss_fn,\n",
    "              accuracy_fn = accuracy_fn,\n",
    "              device = device)\n",
    "    \n",
    "    atest_loss_list.append(loss_test)\n",
    "    atest_acc_list.append(acc_test)\n",
    "\n",
    "train_time_end_model = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_model_2,\n",
    "                                           end=train_time_end_model,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Accuracy for class: circle is 97.4 %\n",
      "Accuracy for class: square is 96.4 %\n",
      "Accuracy for class: star  is 97.4 %\n",
      "Accuracy for class: triangle is 96.9 %\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "\n",
    "\n",
    "correct_pred = {classname: 0 for classname in class_names}\n",
    "total_pred = {classname: 0 for classname in class_names}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_batches:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[class_names[label]] += 1\n",
    "            total_pred[class_names[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "star\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "path = \"star.png\"\n",
    "tf = transforms.Compose([transforms.ToTensor(),\n",
    "                         transforms.Resize((28,28))\n",
    "                \n",
    "                         \n",
    "])\n",
    "\n",
    "img = Image.open(path).convert('L')\n",
    "\n",
    "\n",
    "img_tf = tf(img).float().unsqueeze(0)\n",
    "inverted_img = 1.0 - img_tf  # Subtract each pixel value from 1\n",
    "\n",
    "\n",
    "plt.imshow(img_tf.squeeze())\n",
    "# thresholded_img = (inverted_img > 0.5).float() # Any value > 0.5 becomes 1, else 0\n",
    "\n",
    "plt.imshow(inverted_img.squeeze())\n",
    "# plt.imshow(thresholded_img.squeeze())\n",
    "# thresholded_img = (inverted_img > 0.5).float().to(device)  # Any value > 0.5 becomes 1, else 0\n",
    "\n",
    "inverted_img = inverted_img.to(device)\n",
    "\n",
    "img_tf = img_tf.to(device)\n",
    "\n",
    "\n",
    "print(img_tf.shape)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.forward(inverted_img)\n",
    "    _, y_pred = torch.max(out.data, 1)\n",
    "    print(class_names[y_pred])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
